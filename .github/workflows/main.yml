name: Crawl and Store Data

on:
  workflow_dispatch:
    inputs:
      id:
        description: 'Request ID for this task'
        required: true
      keywords:
        description: 'Comma-separated list of keywords'
        required: false
      csvFile:
        description: 'Base64 encoded CSV file'
        required: false

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Install dependencies
        run: |
          npm install

      - name: Decode Base64 CSV (if provided)
        if: ${{ inputs.csvFile }}
        run: |
          echo "${{ inputs.csvFile }}" | base64 -d > input.csv
        shell: bash

      - name: Run main.js crawler script
        env:
          INPUT_ID: ${{ inputs.id }}
          INPUT_KEYWORDS: ${{ inputs.keywords }}
          INPUT_CSV: ${{ inputs.csvFile && 'input.csv' || '' }}
        run: |
          node main.js "$INPUT_ID" "$INPUT_KEYWORDS" "$INPUT_CSV"

      - name: Commit and Push Results
        run: |
          git config --local user.name "github-actions"
          git config --local user.email "actions@github.com"
          git add results/${{ inputs.id }}.csv
          git commit -m "Add result file for ID ${{ inputs.id }}"
          git push origin main
